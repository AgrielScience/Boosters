{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antoncabanec/anaconda3/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from random import choice\n",
    "from scipy.stats import randint as sp_randint\n",
    "import gc\n",
    "from sklearn.model_selection import TimeSeriesSplit, KFold\n",
    "pd.options.display.max_columns = None\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return sqrt(mean_squared_error(y_true, y_pred))\n",
    "data = pd.read_csv('full_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "data[\"city\"] = labelencoder.fit_transform(data[\"city\"].values.astype('str'))\n",
    "data['city_type'] = labelencoder.fit_transform(data['city_type'].values.astype('str'))\n",
    "data['atm_group'] = labelencoder.fit_transform(data['atm_group'].values.astype('str'))\n",
    "data['dbcluster'] = labelencoder.fit_transform(data['dbcluster'].values.astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[data.isTrain == True].drop(['address', 'address_rus', 'isTrain', 'target'], 1)\n",
    "Y = data[data.isTrain == True][['target']]\n",
    "X_test = data[data.isTrain == False].drop(['address', 'address_rus', 'isTrain', 'target'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_iterations = 20 # number of iterations for random search\n",
    "top_n = 15 # select top n parameter sets\n",
    "\n",
    "rmse_mean = []\n",
    "rmse_std = []\n",
    "dict_list = []\n",
    "# prepare indexes for stratified cross validation\n",
    "skf = KFold(n_splits=5, shuffle=False)\n",
    "skf.get_n_splits(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random search start...\n",
      "\n",
      "Cycle 1...\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's rmse: 0.0555651\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's rmse: 0.0525328\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's rmse: 0.0527631\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's rmse: 0.0540695\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's rmse: 0.0538304\n",
      "Cycle 2...\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0489377\n",
      "[200]\tvalid_0's rmse: 0.0484315\n",
      "[300]\tvalid_0's rmse: 0.0484313\n",
      "[400]\tvalid_0's rmse: 0.0484313\n",
      "[500]\tvalid_0's rmse: 0.0484313\n",
      "[600]\tvalid_0's rmse: 0.0484313\n",
      "[700]\tvalid_0's rmse: 0.0484313\n",
      "Early stopping, best iteration is:\n",
      "[710]\tvalid_0's rmse: 0.0484313\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0469134\n",
      "[200]\tvalid_0's rmse: 0.0464345\n",
      "[300]\tvalid_0's rmse: 0.0464299\n",
      "[400]\tvalid_0's rmse: 0.0464299\n",
      "[500]\tvalid_0's rmse: 0.0464299\n",
      "[600]\tvalid_0's rmse: 0.0464299\n",
      "[700]\tvalid_0's rmse: 0.0464299\n",
      "Early stopping, best iteration is:\n",
      "[719]\tvalid_0's rmse: 0.0464299\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0476086\n",
      "[200]\tvalid_0's rmse: 0.0471238\n",
      "[300]\tvalid_0's rmse: 0.0470753\n",
      "Early stopping, best iteration is:\n",
      "[344]\tvalid_0's rmse: 0.0470715\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0477685\n",
      "[200]\tvalid_0's rmse: 0.0471837\n",
      "[300]\tvalid_0's rmse: 0.0471185\n",
      "[400]\tvalid_0's rmse: 0.047118\n",
      "[500]\tvalid_0's rmse: 0.047118\n",
      "[600]\tvalid_0's rmse: 0.047118\n",
      "[700]\tvalid_0's rmse: 0.047118\n",
      "[800]\tvalid_0's rmse: 0.047118\n",
      "[900]\tvalid_0's rmse: 0.047118\n",
      "Early stopping, best iteration is:\n",
      "[932]\tvalid_0's rmse: 0.047118\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0491478\n",
      "[200]\tvalid_0's rmse: 0.0487613\n",
      "[300]\tvalid_0's rmse: 0.0487609\n",
      "[400]\tvalid_0's rmse: 0.0487609\n",
      "[500]\tvalid_0's rmse: 0.0487609\n",
      "[600]\tvalid_0's rmse: 0.0487609\n",
      "Early stopping, best iteration is:\n",
      "[584]\tvalid_0's rmse: 0.0487609\n",
      "Cycle 3...\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0488646\n",
      "[200]\tvalid_0's rmse: 0.0483234\n",
      "Early stopping, best iteration is:\n",
      "[261]\tvalid_0's rmse: 0.0482493\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.046762\n",
      "[200]\tvalid_0's rmse: 0.0459166\n",
      "[300]\tvalid_0's rmse: 0.0456937\n",
      "Early stopping, best iteration is:\n",
      "[349]\tvalid_0's rmse: 0.0456747\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0470911\n",
      "[200]\tvalid_0's rmse: 0.0465563\n",
      "[300]\tvalid_0's rmse: 0.0464485\n",
      "Early stopping, best iteration is:\n",
      "[365]\tvalid_0's rmse: 0.0462837\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.047368\n",
      "[200]\tvalid_0's rmse: 0.0465125\n",
      "[300]\tvalid_0's rmse: 0.0462852\n",
      "Early stopping, best iteration is:\n",
      "[340]\tvalid_0's rmse: 0.046218\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.048809\n",
      "[200]\tvalid_0's rmse: 0.0483205\n",
      "[300]\tvalid_0's rmse: 0.0481995\n",
      "Early stopping, best iteration is:\n",
      "[313]\tvalid_0's rmse: 0.0481908\n",
      "Cycle 4...\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 0.0886112\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's rmse: 0.0853586\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's rmse: 0.0852452\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 0.0869301\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 0.0831962\n",
      "Cycle 5...\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 0.0886112\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 0.0853586\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's rmse: 0.0852452\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's rmse: 0.0869301\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 0.0831962\n",
      "Cycle 6...\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0580847\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's rmse: 0.055758\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.054964\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's rmse: 0.0527447\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.055483\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's rmse: 0.0533808\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0571441\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's rmse: 0.0548492\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0559627\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's rmse: 0.0540138\n",
      "Cycle 7...\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0705494\n",
      "Early stopping, best iteration is:\n",
      "[171]\tvalid_0's rmse: 0.0691434\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0669005\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's rmse: 0.0654266\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0670187\n",
      "[200]\tvalid_0's rmse: 0.0653406\n",
      "Early stopping, best iteration is:\n",
      "[198]\tvalid_0's rmse: 0.0653406\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0689546\n",
      "Early stopping, best iteration is:\n",
      "[156]\tvalid_0's rmse: 0.0676575\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0657616\n",
      "[200]\tvalid_0's rmse: 0.0643126\n",
      "Early stopping, best iteration is:\n",
      "[198]\tvalid_0's rmse: 0.0643126\n",
      "Cycle 8...\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0525882\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's rmse: 0.0524435\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0501247\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's rmse: 0.0499655\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0504605\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's rmse: 0.0503423\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0519887\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's rmse: 0.0518549\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0515533\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's rmse: 0.0514617\n",
      "Cycle 9...\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's rmse: 0.0489131\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's rmse: 0.0465141\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's rmse: 0.0472836\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's rmse: 0.0477092\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's rmse: 0.0490268\n",
      "Cycle 10...\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0861988\n",
      "[200]\tvalid_0's rmse: 0.0847956\n",
      "[300]\tvalid_0's rmse: 0.0831768\n",
      "[400]\tvalid_0's rmse: 0.0816245\n",
      "[500]\tvalid_0's rmse: 0.0798407\n",
      "Early stopping, best iteration is:\n",
      "[572]\tvalid_0's rmse: 0.0790103\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0828824\n",
      "[200]\tvalid_0's rmse: 0.0814622\n",
      "[300]\tvalid_0's rmse: 0.0798257\n",
      "[400]\tvalid_0's rmse: 0.0782673\n",
      "[500]\tvalid_0's rmse: 0.0764681\n",
      "Early stopping, best iteration is:\n",
      "[572]\tvalid_0's rmse: 0.0756334\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0827622\n",
      "[200]\tvalid_0's rmse: 0.0813593\n",
      "[300]\tvalid_0's rmse: 0.0797405\n",
      "[400]\tvalid_0's rmse: 0.0781959\n",
      "[500]\tvalid_0's rmse: 0.0764179\n",
      "Early stopping, best iteration is:\n",
      "[572]\tvalid_0's rmse: 0.0755902\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0845279\n",
      "[200]\tvalid_0's rmse: 0.08314\n",
      "[300]\tvalid_0's rmse: 0.0815334\n",
      "[400]\tvalid_0's rmse: 0.079995\n",
      "[500]\tvalid_0's rmse: 0.0782254\n",
      "Early stopping, best iteration is:\n",
      "[572]\tvalid_0's rmse: 0.0773976\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0808878\n",
      "[200]\tvalid_0's rmse: 0.0795875\n",
      "[300]\tvalid_0's rmse: 0.0780892\n",
      "[400]\tvalid_0's rmse: 0.0766587\n",
      "[500]\tvalid_0's rmse: 0.0750219\n",
      "Early stopping, best iteration is:\n",
      "[572]\tvalid_0's rmse: 0.0742572\n",
      "Cycle 11...\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0756452\n",
      "[200]\tvalid_0's rmse: 0.0743483\n",
      "[300]\tvalid_0's rmse: 0.0734817\n",
      "Early stopping, best iteration is:\n",
      "[369]\tvalid_0's rmse: 0.0731706\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0721773\n",
      "[200]\tvalid_0's rmse: 0.0703755\n",
      "[300]\tvalid_0's rmse: 0.0691376\n",
      "Early stopping, best iteration is:\n",
      "[303]\tvalid_0's rmse: 0.0691196\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0714842\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's rmse: 0.0714842\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0734104\n",
      "[200]\tvalid_0's rmse: 0.0712995\n",
      "Early stopping, best iteration is:\n",
      "[235]\tvalid_0's rmse: 0.0710784\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0704046\n",
      "[200]\tvalid_0's rmse: 0.0685265\n",
      "Early stopping, best iteration is:\n",
      "[255]\tvalid_0's rmse: 0.0683447\n",
      "Cycle 12...\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 0.0886112\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's rmse: 0.0853521\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's rmse: 0.0852427\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's rmse: 0.086928\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's rmse: 0.0831875\n",
      "Cycle 13...\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0490572\n",
      "[200]\tvalid_0's rmse: 0.0483581\n",
      "[300]\tvalid_0's rmse: 0.0481571\n",
      "[400]\tvalid_0's rmse: 0.0480807\n",
      "Early stopping, best iteration is:\n",
      "[380]\tvalid_0's rmse: 0.0480777\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0472702\n",
      "[200]\tvalid_0's rmse: 0.0464359\n",
      "[300]\tvalid_0's rmse: 0.0462147\n",
      "Early stopping, best iteration is:\n",
      "[331]\tvalid_0's rmse: 0.046128\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.047652\n",
      "[200]\tvalid_0's rmse: 0.0469045\n",
      "[300]\tvalid_0's rmse: 0.0465992\n",
      "Early stopping, best iteration is:\n",
      "[349]\tvalid_0's rmse: 0.0464864\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0478627\n",
      "[200]\tvalid_0's rmse: 0.0469214\n",
      "[300]\tvalid_0's rmse: 0.0466577\n",
      "[400]\tvalid_0's rmse: 0.0465463\n",
      "[500]\tvalid_0's rmse: 0.0464978\n",
      "Early stopping, best iteration is:\n",
      "[556]\tvalid_0's rmse: 0.0464773\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0493963\n",
      "[200]\tvalid_0's rmse: 0.0487282\n",
      "[300]\tvalid_0's rmse: 0.0485381\n",
      "[400]\tvalid_0's rmse: 0.0484754\n",
      "[500]\tvalid_0's rmse: 0.0484108\n",
      "Early stopping, best iteration is:\n",
      "[571]\tvalid_0's rmse: 0.0483888\n",
      "Cycle 14...\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0822001\n",
      "[200]\tvalid_0's rmse: 0.0790766\n",
      "[300]\tvalid_0's rmse: 0.0759762\n",
      "[400]\tvalid_0's rmse: 0.0733369\n",
      "[500]\tvalid_0's rmse: 0.0709616\n",
      "Early stopping, best iteration is:\n",
      "[560]\tvalid_0's rmse: 0.0700905\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.078988\n",
      "[200]\tvalid_0's rmse: 0.0758258\n",
      "[300]\tvalid_0's rmse: 0.0727104\n",
      "[400]\tvalid_0's rmse: 0.0700473\n",
      "[500]\tvalid_0's rmse: 0.0676634\n",
      "Early stopping, best iteration is:\n",
      "[567]\tvalid_0's rmse: 0.06676\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0788434\n",
      "[200]\tvalid_0's rmse: 0.0757558\n",
      "[300]\tvalid_0's rmse: 0.0726575\n",
      "[400]\tvalid_0's rmse: 0.0700461\n",
      "[500]\tvalid_0's rmse: 0.0677034\n",
      "Early stopping, best iteration is:\n",
      "[567]\tvalid_0's rmse: 0.0667965\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0806003\n",
      "[200]\tvalid_0's rmse: 0.077539\n",
      "[300]\tvalid_0's rmse: 0.0745018\n",
      "[400]\tvalid_0's rmse: 0.0719056\n",
      "[500]\tvalid_0's rmse: 0.0695722\n",
      "Early stopping, best iteration is:\n",
      "[567]\tvalid_0's rmse: 0.0686508\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0770486\n",
      "[200]\tvalid_0's rmse: 0.0741611\n",
      "[300]\tvalid_0's rmse: 0.0713036\n",
      "[400]\tvalid_0's rmse: 0.0689155\n",
      "[500]\tvalid_0's rmse: 0.0667699\n",
      "Early stopping, best iteration is:\n",
      "[567]\tvalid_0's rmse: 0.0659399\n",
      "Cycle 15...\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's rmse: 0.0497984\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0482068\n",
      "Early stopping, best iteration is:\n",
      "[156]\tvalid_0's rmse: 0.0482068\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's rmse: 0.0481455\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0491297\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's rmse: 0.0491297\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's rmse: 0.050167\n",
      "Cycle 16...\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's rmse: 0.0478999\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's rmse: 0.0455051\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0464206\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's rmse: 0.0462931\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's rmse: 0.046079\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0480591\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's rmse: 0.0479504\n",
      "Cycle 17...\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0781857\n",
      "[200]\tvalid_0's rmse: 0.0743211\n",
      "[300]\tvalid_0's rmse: 0.072373\n",
      "[400]\tvalid_0's rmse: 0.0712666\n",
      "[500]\tvalid_0's rmse: 0.0708484\n",
      "Early stopping, best iteration is:\n",
      "[529]\tvalid_0's rmse: 0.0707673\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0748918\n",
      "[200]\tvalid_0's rmse: 0.0708691\n",
      "[300]\tvalid_0's rmse: 0.0690717\n",
      "[400]\tvalid_0's rmse: 0.0678433\n",
      "[500]\tvalid_0's rmse: 0.0674734\n",
      "[600]\tvalid_0's rmse: 0.0671769\n",
      "[700]\tvalid_0's rmse: 0.0670018\n",
      "[800]\tvalid_0's rmse: 0.0668471\n",
      "Early stopping, best iteration is:\n",
      "[782]\tvalid_0's rmse: 0.0668471\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0745791\n",
      "[200]\tvalid_0's rmse: 0.0703586\n",
      "[300]\tvalid_0's rmse: 0.0686312\n",
      "[400]\tvalid_0's rmse: 0.0674166\n",
      "[500]\tvalid_0's rmse: 0.0669497\n",
      "[600]\tvalid_0's rmse: 0.0665751\n",
      "[700]\tvalid_0's rmse: 0.0663892\n",
      "[800]\tvalid_0's rmse: 0.0662626\n",
      "Early stopping, best iteration is:\n",
      "[787]\tvalid_0's rmse: 0.0662626\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0765157\n",
      "[200]\tvalid_0's rmse: 0.0723909\n",
      "[300]\tvalid_0's rmse: 0.0707583\n",
      "[400]\tvalid_0's rmse: 0.0696354\n",
      "[500]\tvalid_0's rmse: 0.0692914\n",
      "[600]\tvalid_0's rmse: 0.0689851\n",
      "Early stopping, best iteration is:\n",
      "[645]\tvalid_0's rmse: 0.0688854\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0732424\n",
      "[200]\tvalid_0's rmse: 0.0694439\n",
      "[300]\tvalid_0's rmse: 0.0679194\n",
      "[400]\tvalid_0's rmse: 0.0668867\n",
      "[500]\tvalid_0's rmse: 0.0664971\n",
      "[600]\tvalid_0's rmse: 0.066249\n",
      "[700]\tvalid_0's rmse: 0.0660593\n",
      "[800]\tvalid_0's rmse: 0.0657794\n",
      "Early stopping, best iteration is:\n",
      "[790]\tvalid_0's rmse: 0.0657794\n",
      "Cycle 18...\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0676332\n",
      "[200]\tvalid_0's rmse: 0.0573855\n",
      "[300]\tvalid_0's rmse: 0.0525311\n",
      "[400]\tvalid_0's rmse: 0.0501474\n",
      "[500]\tvalid_0's rmse: 0.0489324\n",
      "[600]\tvalid_0's rmse: 0.048321\n",
      "[700]\tvalid_0's rmse: 0.0479621\n",
      "[800]\tvalid_0's rmse: 0.0477554\n",
      "[900]\tvalid_0's rmse: 0.0476252\n",
      "[1000]\tvalid_0's rmse: 0.0475157\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's rmse: 0.0475156\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0643616\n",
      "[200]\tvalid_0's rmse: 0.054369\n",
      "[300]\tvalid_0's rmse: 0.0499991\n",
      "[400]\tvalid_0's rmse: 0.047983\n",
      "[500]\tvalid_0's rmse: 0.0470416\n",
      "[600]\tvalid_0's rmse: 0.0465847\n",
      "[700]\tvalid_0's rmse: 0.0463107\n",
      "[800]\tvalid_0's rmse: 0.0461139\n",
      "[900]\tvalid_0's rmse: 0.0459823\n",
      "[1000]\tvalid_0's rmse: 0.0458821\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.0458821\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0646631\n",
      "[200]\tvalid_0's rmse: 0.0549413\n",
      "[300]\tvalid_0's rmse: 0.0506761\n",
      "[400]\tvalid_0's rmse: 0.0487008\n",
      "[500]\tvalid_0's rmse: 0.0477107\n",
      "[600]\tvalid_0's rmse: 0.0471597\n",
      "[700]\tvalid_0's rmse: 0.0468044\n",
      "[800]\tvalid_0's rmse: 0.0465894\n",
      "[900]\tvalid_0's rmse: 0.0464597\n",
      "[1000]\tvalid_0's rmse: 0.0463624\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.0463624\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0664507\n",
      "[200]\tvalid_0's rmse: 0.0564933\n",
      "[300]\tvalid_0's rmse: 0.051829\n",
      "[400]\tvalid_0's rmse: 0.0494933\n",
      "[500]\tvalid_0's rmse: 0.0482699\n",
      "[600]\tvalid_0's rmse: 0.0475863\n",
      "[700]\tvalid_0's rmse: 0.0471913\n",
      "[800]\tvalid_0's rmse: 0.0469339\n",
      "[900]\tvalid_0's rmse: 0.046756\n",
      "[1000]\tvalid_0's rmse: 0.046623\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.046623\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0641645\n",
      "[200]\tvalid_0's rmse: 0.0554985\n",
      "[300]\tvalid_0's rmse: 0.0518629\n",
      "[400]\tvalid_0's rmse: 0.0502819\n",
      "[500]\tvalid_0's rmse: 0.0494963\n",
      "[600]\tvalid_0's rmse: 0.0490528\n",
      "[700]\tvalid_0's rmse: 0.0487953\n",
      "[800]\tvalid_0's rmse: 0.0486427\n",
      "[900]\tvalid_0's rmse: 0.0485455\n",
      "[1000]\tvalid_0's rmse: 0.0484794\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.0484794\n",
      "Cycle 19...\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0747085\n",
      "[200]\tvalid_0's rmse: 0.0669764\n",
      "[300]\tvalid_0's rmse: 0.0627634\n",
      "[400]\tvalid_0's rmse: 0.0604565\n",
      "[500]\tvalid_0's rmse: 0.0592308\n",
      "[600]\tvalid_0's rmse: 0.0584894\n",
      "[700]\tvalid_0's rmse: 0.0580344\n",
      "[800]\tvalid_0's rmse: 0.0578203\n",
      "[900]\tvalid_0's rmse: 0.0575772\n",
      "[1000]\tvalid_0's rmse: 0.0574228\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.0574228\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0714108\n",
      "[200]\tvalid_0's rmse: 0.0637735\n",
      "[300]\tvalid_0's rmse: 0.0596702\n",
      "[400]\tvalid_0's rmse: 0.0574535\n",
      "[500]\tvalid_0's rmse: 0.0562688\n",
      "[600]\tvalid_0's rmse: 0.0555836\n",
      "[700]\tvalid_0's rmse: 0.0551294\n",
      "[800]\tvalid_0's rmse: 0.0549318\n",
      "[900]\tvalid_0's rmse: 0.0547082\n",
      "[1000]\tvalid_0's rmse: 0.0545663\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.0545663\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0714586\n",
      "[200]\tvalid_0's rmse: 0.0639451\n",
      "[300]\tvalid_0's rmse: 0.0599242\n",
      "[400]\tvalid_0's rmse: 0.0577513\n",
      "[500]\tvalid_0's rmse: 0.0565662\n",
      "[600]\tvalid_0's rmse: 0.0558558\n",
      "[700]\tvalid_0's rmse: 0.0554696\n",
      "[800]\tvalid_0's rmse: 0.0552635\n",
      "[900]\tvalid_0's rmse: 0.0550308\n",
      "[1000]\tvalid_0's rmse: 0.0548839\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.0548839\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0733175\n",
      "[200]\tvalid_0's rmse: 0.0657379\n",
      "[300]\tvalid_0's rmse: 0.0615908\n",
      "[400]\tvalid_0's rmse: 0.0593018\n",
      "[500]\tvalid_0's rmse: 0.0580601\n",
      "[600]\tvalid_0's rmse: 0.0573227\n",
      "[700]\tvalid_0's rmse: 0.0568716\n",
      "[800]\tvalid_0's rmse: 0.0566573\n",
      "[900]\tvalid_0's rmse: 0.0564147\n",
      "[1000]\tvalid_0's rmse: 0.0562609\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.0562609\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0703057\n",
      "[200]\tvalid_0's rmse: 0.0634253\n",
      "[300]\tvalid_0's rmse: 0.0598167\n",
      "[400]\tvalid_0's rmse: 0.0578974\n",
      "[500]\tvalid_0's rmse: 0.0568878\n",
      "[600]\tvalid_0's rmse: 0.0563076\n",
      "[700]\tvalid_0's rmse: 0.0559525\n",
      "[800]\tvalid_0's rmse: 0.0557879\n",
      "[900]\tvalid_0's rmse: 0.0556046\n",
      "[1000]\tvalid_0's rmse: 0.0554888\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.0554888\n",
      "Cycle 20...\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0524922\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's rmse: 0.0523495\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0500535\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's rmse: 0.0499154\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0507657\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's rmse: 0.0506311\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0517194\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's rmse: 0.051579\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[100]\tvalid_0's rmse: 0.0517223\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's rmse: 0.0516083\n"
     ]
    }
   ],
   "source": [
    "# loop for random search\n",
    "\n",
    "print (\"Random search start...\")\n",
    "print (\"\")\n",
    "\n",
    "for i in range(0, n_iterations):\n",
    "    skf_split = skf.split(X, Y)\n",
    "    param_dist = {'num_leaves': choice([8, 16, 27, 31, 61, 127, 255, 511, 1023, 2047, 4095]),\n",
    "              'feature_fraction': choice([0, 0.3, 0.5, 0.7, 1]),\n",
    "              'bagging_fraction': choice([0.1, 0.3, 0.5, 0.7, 0.8, 0.9, 1]),\n",
    "              'min_data_in_bin': choice([1, 3, 5, 10, 15, 20]),\n",
    "              'min_sum_hessian_in_leaf': choice([1, 5, 10, 20]),\n",
    "              'learning_rate': choice([0.001, 0.005, 0.01, 0.05, 0.1, 0.03, 0.05, 0.3]),\n",
    "              'min_data': choice([50,100, 200, 300, 400, 450, 500, 550, 650]),\n",
    "              'max_bin': choice([3, 5, 7, 10, 12, 18, 20, 22]),\n",
    "              'boosting_type' : choice(['gbdt', 'dart']),\n",
    "              'bagging_freq': choice([3, 5, 7, 9, 11, 15, 17, 23, 31]),\n",
    "              'max_depth': choice([3, 4, 5, 6, 7, 8, 9, 10, 11, 15]),       \n",
    "              'feature_fraction': choice([0.1, 0.3, 0.5, 0.7, 0.8, 0.9, 1]),\n",
    "              'lambda_l1': choice([0, 1, 3, 5, 10, 20, 30, 40]),\n",
    "              'objective': 'regression', \n",
    "              'metric': 'rmse'} \n",
    "    \n",
    "    rmse_metric = []\n",
    "    \n",
    "    print (\"Cycle {}...\".format(i+1))\n",
    "    for train_index, test_index in skf_split:\n",
    "    \n",
    "        X_train = X.iloc[train_index]\n",
    "        y_train = Y.iloc[train_index]\n",
    "    \n",
    "        X_val = X.iloc[test_index]\n",
    "        y_val = Y.iloc[test_index]\n",
    "    \n",
    "        # training\n",
    "        lgb_train = lgb.Dataset(X_train, y_train, free_raw_data=True)\n",
    "        lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train, free_raw_data=True)\n",
    "    \n",
    "        gbm = lgb.train(param_dist,\n",
    "                        lgb_train,\n",
    "                        num_boost_round = 1000,\n",
    "                        valid_sets = lgb_val,\n",
    "                        early_stopping_rounds=25,\n",
    "                        verbose_eval=100)\n",
    "        # predicting\n",
    "        y_pred = gbm.predict(X_val, num_iteration=gbm.best_iteration)\n",
    "        \n",
    "        rmse_i = rmse(y_val, y_pred)\n",
    "        rmse_metric.append(rmse_i)\n",
    "\n",
    "    rmse_array = np.asarray(rmse_metric)\n",
    "    \n",
    "    rmse_mean.append(rmse_array.mean())\n",
    "    rmse_std.append(rmse_array.std())\n",
    "    dict_list.append(param_dist)\n",
    "    gc.collect()\n",
    "\n",
    "results_pd = pd.DataFrame({\"rmse_mean\": rmse_mean,\n",
    "                           \"rmse_std\": rmse_std,\n",
    "                           \"parameters\": dict_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum mean RMSE :  0.04692331776539688 \n",
      "And the parameters list is : \n",
      " {'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.9, 'min_data_in_bin': 15, 'min_sum_hessian_in_leaf': 10, 'learning_rate': 0.05, 'min_data': 500, 'max_bin': 20, 'boosting_type': 'gbdt', 'bagging_freq': 17, 'max_depth': 3, 'lambda_l1': 3, 'objective': 'regression', 'metric': 'rmse'}\n"
     ]
    }
   ],
   "source": [
    "z = results_pd.sort_values('rmse_mean').copy().reset_index()\n",
    "print(\"Minimum mean RMSE : \", z.rmse_mean.min(), \"\\nAnd the parameters list is : \\n\", z.parameters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params = {'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.9, 'min_data_in_bin': 15, \n",
    "#          'min_sum_hessian_in_leaf': 10, 'learning_rate': 0.05, 'min_data': 500, 'max_bin': 20, \n",
    "#           'boosting_type': 'gbdt', 'bagging_freq': 17, 'max_depth': 3, 'lambda_l1': 3,\n",
    "#           'objective': 'regression', 'metric': 'rmse'}\n",
    "params = z.parameters[0]\n",
    "n_fold = 5\n",
    "folds = KFold(n_splits=n_fold, shuffle=False, random_state=42)\n",
    "# Cleaning and defining parameters for LGBM\n",
    "model = lgb.LGBMRegressor(**params, n_estimators = 20000, nthread = 4, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[261]\ttraining's rmse: 0.0457342\tvalid_1's rmse: 0.0482493\n",
      "Fold: 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\ttraining's rmse: 0.0461731\tvalid_1's rmse: 0.0456108\n",
      "Early stopping, best iteration is:\n",
      "[451]\ttraining's rmse: 0.0461794\tvalid_1's rmse: 0.0456105\n",
      "Fold: 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\ttraining's rmse: 0.0458966\tvalid_1's rmse: 0.0462623\n",
      "Early stopping, best iteration is:\n",
      "[406]\ttraining's rmse: 0.0458975\tvalid_1's rmse: 0.0462614\n",
      "Fold: 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[338]\ttraining's rmse: 0.0460163\tvalid_1's rmse: 0.046218\n",
      "Fold: 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[385]\ttraining's rmse: 0.0454843\tvalid_1's rmse: 0.0481885\n"
     ]
    }
   ],
   "source": [
    "prediction = np.zeros(X_test.shape[0])\n",
    "\n",
    "for fold_n, (train_index, test_index) in enumerate(folds.split(X)):\n",
    "    print('Fold:', fold_n)\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_train, Y_valid = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "    model.fit(X_train, Y_train, \n",
    "            eval_set=[(X_train, Y_train), (X_valid, Y_valid)], eval_metric='rmse',\n",
    "            verbose=500, early_stopping_rounds=100)\n",
    "    \n",
    "    y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "    prediction += y_pred\n",
    "prediction /= n_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a146393c8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lgb.plot_importance(model, max_num_features=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(prediction, index=test.index, columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.reset_index(level=0, inplace=True)\n",
    "submission.index.name = \"\"\n",
    "submission.to_csv('lgb_submit.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = lgb.LGBMRegressor(objective = 'regression',  \n",
    "                            max_depth = 3,\n",
    "                            colsample_bytre = 0.8,\n",
    "                            subsample = 0.8, \n",
    "                            learning_rate = 0.1,\n",
    "                            n_estimators = 30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's rmse: 0.0790925\tvalid_0's l2: 0.00625562\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\tvalid_0's rmse: 0.0742903\tvalid_0's l2: 0.00551904\n",
      "[3]\tvalid_0's rmse: 0.0701349\tvalid_0's l2: 0.00491891\n",
      "[4]\tvalid_0's rmse: 0.0665312\tvalid_0's l2: 0.00442641\n",
      "[5]\tvalid_0's rmse: 0.063494\tvalid_0's l2: 0.00403148\n",
      "[6]\tvalid_0's rmse: 0.0609422\tvalid_0's l2: 0.00371395\n",
      "[7]\tvalid_0's rmse: 0.0587009\tvalid_0's l2: 0.00344579\n",
      "[8]\tvalid_0's rmse: 0.0568008\tvalid_0's l2: 0.00322633\n",
      "[9]\tvalid_0's rmse: 0.0551742\tvalid_0's l2: 0.00304419\n",
      "[10]\tvalid_0's rmse: 0.0538593\tvalid_0's l2: 0.00290082\n",
      "[11]\tvalid_0's rmse: 0.0527321\tvalid_0's l2: 0.00278067\n",
      "[12]\tvalid_0's rmse: 0.0517598\tvalid_0's l2: 0.00267908\n",
      "[13]\tvalid_0's rmse: 0.0509299\tvalid_0's l2: 0.00259386\n",
      "[14]\tvalid_0's rmse: 0.0502772\tvalid_0's l2: 0.0025278\n",
      "[15]\tvalid_0's rmse: 0.0496464\tvalid_0's l2: 0.00246476\n",
      "[16]\tvalid_0's rmse: 0.0491529\tvalid_0's l2: 0.00241601\n",
      "[17]\tvalid_0's rmse: 0.0487459\tvalid_0's l2: 0.00237617\n",
      "[18]\tvalid_0's rmse: 0.0483842\tvalid_0's l2: 0.00234103\n",
      "[19]\tvalid_0's rmse: 0.0481142\tvalid_0's l2: 0.00231498\n",
      "[20]\tvalid_0's rmse: 0.04784\tvalid_0's l2: 0.00228867\n",
      "[21]\tvalid_0's rmse: 0.047588\tvalid_0's l2: 0.00226461\n",
      "[22]\tvalid_0's rmse: 0.0474038\tvalid_0's l2: 0.00224712\n",
      "[23]\tvalid_0's rmse: 0.0472542\tvalid_0's l2: 0.00223296\n",
      "[24]\tvalid_0's rmse: 0.0471279\tvalid_0's l2: 0.00222104\n",
      "[25]\tvalid_0's rmse: 0.0469997\tvalid_0's l2: 0.00220897\n",
      "[26]\tvalid_0's rmse: 0.0469397\tvalid_0's l2: 0.00220334\n",
      "[27]\tvalid_0's rmse: 0.0468243\tvalid_0's l2: 0.00219251\n",
      "[28]\tvalid_0's rmse: 0.0467318\tvalid_0's l2: 0.00218386\n",
      "[29]\tvalid_0's rmse: 0.0466557\tvalid_0's l2: 0.00217675\n",
      "[30]\tvalid_0's rmse: 0.0466081\tvalid_0's l2: 0.00217232\n",
      "[31]\tvalid_0's rmse: 0.0465385\tvalid_0's l2: 0.00216584\n",
      "[32]\tvalid_0's rmse: 0.0464864\tvalid_0's l2: 0.00216098\n",
      "[33]\tvalid_0's rmse: 0.0464518\tvalid_0's l2: 0.00215777\n",
      "[34]\tvalid_0's rmse: 0.0464159\tvalid_0's l2: 0.00215443\n",
      "[35]\tvalid_0's rmse: 0.0463633\tvalid_0's l2: 0.00214956\n",
      "[36]\tvalid_0's rmse: 0.0463238\tvalid_0's l2: 0.0021459\n",
      "[37]\tvalid_0's rmse: 0.0462857\tvalid_0's l2: 0.00214237\n",
      "[38]\tvalid_0's rmse: 0.0462877\tvalid_0's l2: 0.00214255\n",
      "[39]\tvalid_0's rmse: 0.0462569\tvalid_0's l2: 0.0021397\n",
      "[40]\tvalid_0's rmse: 0.0462164\tvalid_0's l2: 0.00213595\n",
      "[41]\tvalid_0's rmse: 0.0461864\tvalid_0's l2: 0.00213318\n",
      "[42]\tvalid_0's rmse: 0.046184\tvalid_0's l2: 0.00213296\n",
      "[43]\tvalid_0's rmse: 0.0461721\tvalid_0's l2: 0.00213186\n",
      "[44]\tvalid_0's rmse: 0.0461354\tvalid_0's l2: 0.00212848\n",
      "[45]\tvalid_0's rmse: 0.0461413\tvalid_0's l2: 0.00212902\n",
      "[46]\tvalid_0's rmse: 0.0461154\tvalid_0's l2: 0.00212663\n",
      "[47]\tvalid_0's rmse: 0.0460839\tvalid_0's l2: 0.00212372\n",
      "[48]\tvalid_0's rmse: 0.0460681\tvalid_0's l2: 0.00212227\n",
      "[49]\tvalid_0's rmse: 0.0460738\tvalid_0's l2: 0.00212279\n",
      "[50]\tvalid_0's rmse: 0.0460872\tvalid_0's l2: 0.00212403\n",
      "[51]\tvalid_0's rmse: 0.0460734\tvalid_0's l2: 0.00212276\n",
      "[52]\tvalid_0's rmse: 0.0460286\tvalid_0's l2: 0.00211863\n",
      "[53]\tvalid_0's rmse: 0.0460198\tvalid_0's l2: 0.00211782\n",
      "[54]\tvalid_0's rmse: 0.0460157\tvalid_0's l2: 0.00211744\n",
      "[55]\tvalid_0's rmse: 0.0460069\tvalid_0's l2: 0.00211663\n",
      "[56]\tvalid_0's rmse: 0.0460088\tvalid_0's l2: 0.00211681\n",
      "[57]\tvalid_0's rmse: 0.0459836\tvalid_0's l2: 0.00211449\n",
      "[58]\tvalid_0's rmse: 0.0459792\tvalid_0's l2: 0.00211409\n",
      "[59]\tvalid_0's rmse: 0.0459517\tvalid_0's l2: 0.00211156\n",
      "[60]\tvalid_0's rmse: 0.0459575\tvalid_0's l2: 0.00211209\n",
      "[61]\tvalid_0's rmse: 0.0459432\tvalid_0's l2: 0.00211077\n",
      "[62]\tvalid_0's rmse: 0.0459221\tvalid_0's l2: 0.00210884\n",
      "[63]\tvalid_0's rmse: 0.0459103\tvalid_0's l2: 0.00210775\n",
      "[64]\tvalid_0's rmse: 0.0459068\tvalid_0's l2: 0.00210743\n",
      "[65]\tvalid_0's rmse: 0.0459046\tvalid_0's l2: 0.00210723\n",
      "[66]\tvalid_0's rmse: 0.0459159\tvalid_0's l2: 0.00210827\n",
      "[67]\tvalid_0's rmse: 0.0459343\tvalid_0's l2: 0.00210996\n",
      "[68]\tvalid_0's rmse: 0.0459306\tvalid_0's l2: 0.00210962\n",
      "[69]\tvalid_0's rmse: 0.0458904\tvalid_0's l2: 0.00210593\n",
      "[70]\tvalid_0's rmse: 0.0458892\tvalid_0's l2: 0.00210582\n",
      "[71]\tvalid_0's rmse: 0.0458777\tvalid_0's l2: 0.00210476\n",
      "[72]\tvalid_0's rmse: 0.0458452\tvalid_0's l2: 0.00210178\n",
      "[73]\tvalid_0's rmse: 0.045847\tvalid_0's l2: 0.00210195\n",
      "[74]\tvalid_0's rmse: 0.0458482\tvalid_0's l2: 0.00210206\n",
      "[75]\tvalid_0's rmse: 0.0458308\tvalid_0's l2: 0.00210046\n",
      "[76]\tvalid_0's rmse: 0.0457854\tvalid_0's l2: 0.00209631\n",
      "[77]\tvalid_0's rmse: 0.0457764\tvalid_0's l2: 0.00209548\n",
      "[78]\tvalid_0's rmse: 0.0457461\tvalid_0's l2: 0.00209271\n",
      "[79]\tvalid_0's rmse: 0.0457349\tvalid_0's l2: 0.00209168\n",
      "[80]\tvalid_0's rmse: 0.0457428\tvalid_0's l2: 0.00209241\n",
      "[81]\tvalid_0's rmse: 0.0457384\tvalid_0's l2: 0.002092\n",
      "[82]\tvalid_0's rmse: 0.0457384\tvalid_0's l2: 0.002092\n",
      "[83]\tvalid_0's rmse: 0.0457035\tvalid_0's l2: 0.00208881\n",
      "[84]\tvalid_0's rmse: 0.0456733\tvalid_0's l2: 0.00208605\n",
      "[85]\tvalid_0's rmse: 0.0456785\tvalid_0's l2: 0.00208652\n",
      "[86]\tvalid_0's rmse: 0.045704\tvalid_0's l2: 0.00208886\n",
      "[87]\tvalid_0's rmse: 0.0457198\tvalid_0's l2: 0.0020903\n",
      "[88]\tvalid_0's rmse: 0.0457319\tvalid_0's l2: 0.0020914\n",
      "[89]\tvalid_0's rmse: 0.0457073\tvalid_0's l2: 0.00208916\n",
      "[90]\tvalid_0's rmse: 0.0457306\tvalid_0's l2: 0.00209128\n",
      "[91]\tvalid_0's rmse: 0.0457273\tvalid_0's l2: 0.00209099\n",
      "[92]\tvalid_0's rmse: 0.0457152\tvalid_0's l2: 0.00208988\n",
      "[93]\tvalid_0's rmse: 0.0457145\tvalid_0's l2: 0.00208982\n",
      "[94]\tvalid_0's rmse: 0.0457006\tvalid_0's l2: 0.00208855\n",
      "[95]\tvalid_0's rmse: 0.0456894\tvalid_0's l2: 0.00208752\n",
      "[96]\tvalid_0's rmse: 0.0456803\tvalid_0's l2: 0.00208669\n",
      "[97]\tvalid_0's rmse: 0.0456811\tvalid_0's l2: 0.00208677\n",
      "[98]\tvalid_0's rmse: 0.0456863\tvalid_0's l2: 0.00208724\n",
      "[99]\tvalid_0's rmse: 0.0456755\tvalid_0's l2: 0.00208625\n",
      "[100]\tvalid_0's rmse: 0.0456733\tvalid_0's l2: 0.00208605\n",
      "[101]\tvalid_0's rmse: 0.0456659\tvalid_0's l2: 0.00208537\n",
      "[102]\tvalid_0's rmse: 0.0456709\tvalid_0's l2: 0.00208583\n",
      "[103]\tvalid_0's rmse: 0.0456395\tvalid_0's l2: 0.00208296\n",
      "[104]\tvalid_0's rmse: 0.0456292\tvalid_0's l2: 0.00208203\n",
      "[105]\tvalid_0's rmse: 0.0456301\tvalid_0's l2: 0.0020821\n",
      "[106]\tvalid_0's rmse: 0.0456179\tvalid_0's l2: 0.002081\n",
      "[107]\tvalid_0's rmse: 0.0455977\tvalid_0's l2: 0.00207915\n",
      "[108]\tvalid_0's rmse: 0.0456074\tvalid_0's l2: 0.00208004\n",
      "[109]\tvalid_0's rmse: 0.0455841\tvalid_0's l2: 0.00207791\n",
      "[110]\tvalid_0's rmse: 0.045572\tvalid_0's l2: 0.0020768\n",
      "[111]\tvalid_0's rmse: 0.0455899\tvalid_0's l2: 0.00207844\n",
      "[112]\tvalid_0's rmse: 0.0455787\tvalid_0's l2: 0.00207742\n",
      "[113]\tvalid_0's rmse: 0.0455582\tvalid_0's l2: 0.00207555\n",
      "[114]\tvalid_0's rmse: 0.0455474\tvalid_0's l2: 0.00207457\n",
      "[115]\tvalid_0's rmse: 0.0455536\tvalid_0's l2: 0.00207513\n",
      "[116]\tvalid_0's rmse: 0.0455585\tvalid_0's l2: 0.00207558\n",
      "[117]\tvalid_0's rmse: 0.0455566\tvalid_0's l2: 0.00207541\n",
      "[118]\tvalid_0's rmse: 0.0455521\tvalid_0's l2: 0.00207499\n",
      "[119]\tvalid_0's rmse: 0.0455472\tvalid_0's l2: 0.00207455\n",
      "[120]\tvalid_0's rmse: 0.0455561\tvalid_0's l2: 0.00207535\n",
      "[121]\tvalid_0's rmse: 0.0455768\tvalid_0's l2: 0.00207724\n",
      "[122]\tvalid_0's rmse: 0.0455753\tvalid_0's l2: 0.00207711\n",
      "[123]\tvalid_0's rmse: 0.0455667\tvalid_0's l2: 0.00207633\n",
      "[124]\tvalid_0's rmse: 0.0455673\tvalid_0's l2: 0.00207638\n",
      "[125]\tvalid_0's rmse: 0.0455682\tvalid_0's l2: 0.00207646\n",
      "[126]\tvalid_0's rmse: 0.0455624\tvalid_0's l2: 0.00207593\n",
      "[127]\tvalid_0's rmse: 0.0455731\tvalid_0's l2: 0.00207691\n",
      "[128]\tvalid_0's rmse: 0.0455759\tvalid_0's l2: 0.00207716\n",
      "[129]\tvalid_0's rmse: 0.0455738\tvalid_0's l2: 0.00207697\n",
      "[130]\tvalid_0's rmse: 0.0455873\tvalid_0's l2: 0.0020782\n",
      "[131]\tvalid_0's rmse: 0.0455862\tvalid_0's l2: 0.0020781\n",
      "[132]\tvalid_0's rmse: 0.045578\tvalid_0's l2: 0.00207735\n",
      "[133]\tvalid_0's rmse: 0.045567\tvalid_0's l2: 0.00207635\n",
      "[134]\tvalid_0's rmse: 0.0455713\tvalid_0's l2: 0.00207674\n",
      "[135]\tvalid_0's rmse: 0.0455966\tvalid_0's l2: 0.00207905\n",
      "[136]\tvalid_0's rmse: 0.0455926\tvalid_0's l2: 0.00207869\n",
      "[137]\tvalid_0's rmse: 0.0455574\tvalid_0's l2: 0.00207548\n",
      "[138]\tvalid_0's rmse: 0.0455497\tvalid_0's l2: 0.00207478\n",
      "[139]\tvalid_0's rmse: 0.0455489\tvalid_0's l2: 0.0020747\n",
      "[140]\tvalid_0's rmse: 0.0455524\tvalid_0's l2: 0.00207502\n",
      "[141]\tvalid_0's rmse: 0.0455415\tvalid_0's l2: 0.00207403\n",
      "[142]\tvalid_0's rmse: 0.0455317\tvalid_0's l2: 0.00207313\n",
      "[143]\tvalid_0's rmse: 0.0455327\tvalid_0's l2: 0.00207323\n",
      "[144]\tvalid_0's rmse: 0.0455418\tvalid_0's l2: 0.00207406\n",
      "[145]\tvalid_0's rmse: 0.0455401\tvalid_0's l2: 0.0020739\n",
      "[146]\tvalid_0's rmse: 0.045534\tvalid_0's l2: 0.00207335\n",
      "[147]\tvalid_0's rmse: 0.0455308\tvalid_0's l2: 0.00207305\n",
      "[148]\tvalid_0's rmse: 0.0455312\tvalid_0's l2: 0.00207309\n",
      "[149]\tvalid_0's rmse: 0.0455168\tvalid_0's l2: 0.00207178\n",
      "[150]\tvalid_0's rmse: 0.0455091\tvalid_0's l2: 0.00207108\n",
      "[151]\tvalid_0's rmse: 0.0454645\tvalid_0's l2: 0.00206702\n",
      "[152]\tvalid_0's rmse: 0.0454637\tvalid_0's l2: 0.00206695\n",
      "[153]\tvalid_0's rmse: 0.0454741\tvalid_0's l2: 0.00206789\n",
      "[154]\tvalid_0's rmse: 0.0454847\tvalid_0's l2: 0.00206886\n",
      "[155]\tvalid_0's rmse: 0.0454771\tvalid_0's l2: 0.00206817\n",
      "[156]\tvalid_0's rmse: 0.0454777\tvalid_0's l2: 0.00206822\n",
      "[157]\tvalid_0's rmse: 0.0454626\tvalid_0's l2: 0.00206685\n",
      "[158]\tvalid_0's rmse: 0.0454616\tvalid_0's l2: 0.00206676\n",
      "[159]\tvalid_0's rmse: 0.0454313\tvalid_0's l2: 0.002064\n",
      "[160]\tvalid_0's rmse: 0.045425\tvalid_0's l2: 0.00206343\n",
      "[161]\tvalid_0's rmse: 0.0454204\tvalid_0's l2: 0.00206301\n",
      "[162]\tvalid_0's rmse: 0.0454177\tvalid_0's l2: 0.00206277\n",
      "[163]\tvalid_0's rmse: 0.0454209\tvalid_0's l2: 0.00206306\n",
      "[164]\tvalid_0's rmse: 0.0454294\tvalid_0's l2: 0.00206383\n",
      "[165]\tvalid_0's rmse: 0.0454186\tvalid_0's l2: 0.00206285\n",
      "[166]\tvalid_0's rmse: 0.0453978\tvalid_0's l2: 0.00206096\n",
      "[167]\tvalid_0's rmse: 0.0453961\tvalid_0's l2: 0.00206081\n",
      "[168]\tvalid_0's rmse: 0.0453793\tvalid_0's l2: 0.00205928\n",
      "[169]\tvalid_0's rmse: 0.0453696\tvalid_0's l2: 0.0020584\n",
      "[170]\tvalid_0's rmse: 0.0453694\tvalid_0's l2: 0.00205839\n",
      "[171]\tvalid_0's rmse: 0.0453628\tvalid_0's l2: 0.00205778\n",
      "[172]\tvalid_0's rmse: 0.0453726\tvalid_0's l2: 0.00205867\n",
      "[173]\tvalid_0's rmse: 0.045362\tvalid_0's l2: 0.00205771\n",
      "[174]\tvalid_0's rmse: 0.0453602\tvalid_0's l2: 0.00205755\n",
      "[175]\tvalid_0's rmse: 0.0453706\tvalid_0's l2: 0.00205849\n",
      "[176]\tvalid_0's rmse: 0.0453916\tvalid_0's l2: 0.00206039\n",
      "[177]\tvalid_0's rmse: 0.0454002\tvalid_0's l2: 0.00206118\n",
      "[178]\tvalid_0's rmse: 0.0454107\tvalid_0's l2: 0.00206213\n",
      "[179]\tvalid_0's rmse: 0.0453916\tvalid_0's l2: 0.0020604\n",
      "[180]\tvalid_0's rmse: 0.0454008\tvalid_0's l2: 0.00206124\n",
      "[181]\tvalid_0's rmse: 0.0453973\tvalid_0's l2: 0.00206092\n",
      "[182]\tvalid_0's rmse: 0.0453845\tvalid_0's l2: 0.00205975\n",
      "[183]\tvalid_0's rmse: 0.0453764\tvalid_0's l2: 0.00205902\n",
      "[184]\tvalid_0's rmse: 0.0453939\tvalid_0's l2: 0.0020606\n",
      "[185]\tvalid_0's rmse: 0.0454044\tvalid_0's l2: 0.00206156\n",
      "[186]\tvalid_0's rmse: 0.0454205\tvalid_0's l2: 0.00206302\n",
      "[187]\tvalid_0's rmse: 0.0453941\tvalid_0's l2: 0.00206062\n",
      "[188]\tvalid_0's rmse: 0.0453882\tvalid_0's l2: 0.00206009\n",
      "[189]\tvalid_0's rmse: 0.0453731\tvalid_0's l2: 0.00205872\n",
      "[190]\tvalid_0's rmse: 0.0453532\tvalid_0's l2: 0.00205691\n",
      "[191]\tvalid_0's rmse: 0.04536\tvalid_0's l2: 0.00205753\n",
      "[192]\tvalid_0's rmse: 0.0453607\tvalid_0's l2: 0.00205759\n",
      "[193]\tvalid_0's rmse: 0.0453564\tvalid_0's l2: 0.0020572\n",
      "[194]\tvalid_0's rmse: 0.0453535\tvalid_0's l2: 0.00205694\n",
      "[195]\tvalid_0's rmse: 0.0453307\tvalid_0's l2: 0.00205488\n",
      "[196]\tvalid_0's rmse: 0.0453297\tvalid_0's l2: 0.00205478\n",
      "[197]\tvalid_0's rmse: 0.0453236\tvalid_0's l2: 0.00205423\n",
      "[198]\tvalid_0's rmse: 0.0453228\tvalid_0's l2: 0.00205416\n",
      "[199]\tvalid_0's rmse: 0.0453344\tvalid_0's l2: 0.00205521\n",
      "[200]\tvalid_0's rmse: 0.0453174\tvalid_0's l2: 0.00205367\n",
      "[201]\tvalid_0's rmse: 0.0453058\tvalid_0's l2: 0.00205262\n",
      "[202]\tvalid_0's rmse: 0.0452959\tvalid_0's l2: 0.00205172\n",
      "[203]\tvalid_0's rmse: 0.0452959\tvalid_0's l2: 0.00205172\n",
      "[204]\tvalid_0's rmse: 0.0452751\tvalid_0's l2: 0.00204983\n",
      "[205]\tvalid_0's rmse: 0.0452675\tvalid_0's l2: 0.00204914\n",
      "[206]\tvalid_0's rmse: 0.0452602\tvalid_0's l2: 0.00204849\n",
      "[207]\tvalid_0's rmse: 0.0452644\tvalid_0's l2: 0.00204886\n",
      "[208]\tvalid_0's rmse: 0.0452629\tvalid_0's l2: 0.00204873\n",
      "[209]\tvalid_0's rmse: 0.0452657\tvalid_0's l2: 0.00204899\n",
      "[210]\tvalid_0's rmse: 0.0452612\tvalid_0's l2: 0.00204858\n",
      "[211]\tvalid_0's rmse: 0.0452364\tvalid_0's l2: 0.00204633\n",
      "[212]\tvalid_0's rmse: 0.0452344\tvalid_0's l2: 0.00204615\n",
      "[213]\tvalid_0's rmse: 0.0452427\tvalid_0's l2: 0.0020469\n",
      "[214]\tvalid_0's rmse: 0.0452387\tvalid_0's l2: 0.00204654\n",
      "[215]\tvalid_0's rmse: 0.0452429\tvalid_0's l2: 0.00204692\n",
      "[216]\tvalid_0's rmse: 0.0452389\tvalid_0's l2: 0.00204656\n",
      "[217]\tvalid_0's rmse: 0.0452221\tvalid_0's l2: 0.00204504\n",
      "[218]\tvalid_0's rmse: 0.0452219\tvalid_0's l2: 0.00204502\n",
      "[219]\tvalid_0's rmse: 0.0452233\tvalid_0's l2: 0.00204515\n",
      "[220]\tvalid_0's rmse: 0.0452189\tvalid_0's l2: 0.00204475\n",
      "[221]\tvalid_0's rmse: 0.0452169\tvalid_0's l2: 0.00204457\n",
      "[222]\tvalid_0's rmse: 0.045217\tvalid_0's l2: 0.00204458\n",
      "[223]\tvalid_0's rmse: 0.0452182\tvalid_0's l2: 0.00204469\n",
      "[224]\tvalid_0's rmse: 0.0452248\tvalid_0's l2: 0.00204528\n",
      "[225]\tvalid_0's rmse: 0.0452251\tvalid_0's l2: 0.00204531\n",
      "[226]\tvalid_0's rmse: 0.0452292\tvalid_0's l2: 0.00204568\n",
      "[227]\tvalid_0's rmse: 0.0452382\tvalid_0's l2: 0.00204649\n",
      "[228]\tvalid_0's rmse: 0.0452432\tvalid_0's l2: 0.00204695\n",
      "[229]\tvalid_0's rmse: 0.0452486\tvalid_0's l2: 0.00204744\n",
      "[230]\tvalid_0's rmse: 0.0452513\tvalid_0's l2: 0.00204768\n",
      "[231]\tvalid_0's rmse: 0.0452462\tvalid_0's l2: 0.00204722\n",
      "[232]\tvalid_0's rmse: 0.0452406\tvalid_0's l2: 0.00204671\n",
      "[233]\tvalid_0's rmse: 0.0452484\tvalid_0's l2: 0.00204742\n",
      "[234]\tvalid_0's rmse: 0.0452481\tvalid_0's l2: 0.00204739\n",
      "[235]\tvalid_0's rmse: 0.0452455\tvalid_0's l2: 0.00204716\n",
      "[236]\tvalid_0's rmse: 0.0452539\tvalid_0's l2: 0.00204792\n",
      "[237]\tvalid_0's rmse: 0.0452488\tvalid_0's l2: 0.00204745\n",
      "[238]\tvalid_0's rmse: 0.0452379\tvalid_0's l2: 0.00204646\n",
      "[239]\tvalid_0's rmse: 0.0452237\tvalid_0's l2: 0.00204518\n",
      "[240]\tvalid_0's rmse: 0.045224\tvalid_0's l2: 0.00204521\n",
      "[241]\tvalid_0's rmse: 0.045214\tvalid_0's l2: 0.0020443\n",
      "[242]\tvalid_0's rmse: 0.0452166\tvalid_0's l2: 0.00204454\n",
      "[243]\tvalid_0's rmse: 0.0452208\tvalid_0's l2: 0.00204492\n",
      "[244]\tvalid_0's rmse: 0.0452205\tvalid_0's l2: 0.0020449\n",
      "[245]\tvalid_0's rmse: 0.045202\tvalid_0's l2: 0.00204322\n",
      "[246]\tvalid_0's rmse: 0.0452006\tvalid_0's l2: 0.0020431\n",
      "[247]\tvalid_0's rmse: 0.0452027\tvalid_0's l2: 0.00204329\n",
      "[248]\tvalid_0's rmse: 0.0452028\tvalid_0's l2: 0.00204329\n",
      "[249]\tvalid_0's rmse: 0.0452236\tvalid_0's l2: 0.00204517\n",
      "[250]\tvalid_0's rmse: 0.0452166\tvalid_0's l2: 0.00204454\n",
      "[251]\tvalid_0's rmse: 0.0452128\tvalid_0's l2: 0.0020442\n",
      "[252]\tvalid_0's rmse: 0.0452231\tvalid_0's l2: 0.00204513\n",
      "[253]\tvalid_0's rmse: 0.0452188\tvalid_0's l2: 0.00204474\n",
      "[254]\tvalid_0's rmse: 0.0452251\tvalid_0's l2: 0.00204531\n",
      "[255]\tvalid_0's rmse: 0.0452225\tvalid_0's l2: 0.00204507\n",
      "[256]\tvalid_0's rmse: 0.0451957\tvalid_0's l2: 0.00204265\n",
      "[257]\tvalid_0's rmse: 0.0451875\tvalid_0's l2: 0.00204191\n",
      "[258]\tvalid_0's rmse: 0.0451866\tvalid_0's l2: 0.00204183\n",
      "[259]\tvalid_0's rmse: 0.0451709\tvalid_0's l2: 0.00204041\n",
      "[260]\tvalid_0's rmse: 0.0451872\tvalid_0's l2: 0.00204188\n",
      "[261]\tvalid_0's rmse: 0.04517\tvalid_0's l2: 0.00204033\n",
      "[262]\tvalid_0's rmse: 0.0451595\tvalid_0's l2: 0.00203938\n",
      "[263]\tvalid_0's rmse: 0.0451584\tvalid_0's l2: 0.00203928\n",
      "[264]\tvalid_0's rmse: 0.0451604\tvalid_0's l2: 0.00203946\n",
      "[265]\tvalid_0's rmse: 0.0451577\tvalid_0's l2: 0.00203922\n",
      "[266]\tvalid_0's rmse: 0.0451522\tvalid_0's l2: 0.00203872\n",
      "[267]\tvalid_0's rmse: 0.0451369\tvalid_0's l2: 0.00203734\n",
      "[268]\tvalid_0's rmse: 0.0451297\tvalid_0's l2: 0.00203669\n",
      "[269]\tvalid_0's rmse: 0.0451228\tvalid_0's l2: 0.00203607\n",
      "[270]\tvalid_0's rmse: 0.0451028\tvalid_0's l2: 0.00203426\n",
      "[271]\tvalid_0's rmse: 0.0450932\tvalid_0's l2: 0.00203339\n",
      "[272]\tvalid_0's rmse: 0.0450858\tvalid_0's l2: 0.00203273\n",
      "[273]\tvalid_0's rmse: 0.0450696\tvalid_0's l2: 0.00203127\n",
      "[274]\tvalid_0's rmse: 0.0450734\tvalid_0's l2: 0.00203161\n",
      "[275]\tvalid_0's rmse: 0.0450738\tvalid_0's l2: 0.00203165\n",
      "[276]\tvalid_0's rmse: 0.0450797\tvalid_0's l2: 0.00203218\n",
      "[277]\tvalid_0's rmse: 0.0450783\tvalid_0's l2: 0.00203205\n",
      "[278]\tvalid_0's rmse: 0.0450963\tvalid_0's l2: 0.00203367\n",
      "[279]\tvalid_0's rmse: 0.0450887\tvalid_0's l2: 0.00203299\n",
      "[280]\tvalid_0's rmse: 0.0450883\tvalid_0's l2: 0.00203296\n",
      "[281]\tvalid_0's rmse: 0.0450925\tvalid_0's l2: 0.00203334\n",
      "[282]\tvalid_0's rmse: 0.0450812\tvalid_0's l2: 0.00203232\n",
      "[283]\tvalid_0's rmse: 0.0450867\tvalid_0's l2: 0.00203281\n",
      "[284]\tvalid_0's rmse: 0.0450748\tvalid_0's l2: 0.00203174\n",
      "[285]\tvalid_0's rmse: 0.0450766\tvalid_0's l2: 0.0020319\n",
      "[286]\tvalid_0's rmse: 0.045063\tvalid_0's l2: 0.00203067\n",
      "[287]\tvalid_0's rmse: 0.0450679\tvalid_0's l2: 0.00203111\n",
      "[288]\tvalid_0's rmse: 0.0450468\tvalid_0's l2: 0.00202921\n",
      "[289]\tvalid_0's rmse: 0.0450466\tvalid_0's l2: 0.0020292\n",
      "[290]\tvalid_0's rmse: 0.0450525\tvalid_0's l2: 0.00202973\n",
      "[291]\tvalid_0's rmse: 0.0450495\tvalid_0's l2: 0.00202946\n",
      "[292]\tvalid_0's rmse: 0.0450444\tvalid_0's l2: 0.002029\n",
      "[293]\tvalid_0's rmse: 0.0450441\tvalid_0's l2: 0.00202897\n",
      "[294]\tvalid_0's rmse: 0.0450411\tvalid_0's l2: 0.0020287\n",
      "[295]\tvalid_0's rmse: 0.0450386\tvalid_0's l2: 0.00202847\n",
      "[296]\tvalid_0's rmse: 0.0450437\tvalid_0's l2: 0.00202893\n",
      "[297]\tvalid_0's rmse: 0.0450312\tvalid_0's l2: 0.00202781\n",
      "[298]\tvalid_0's rmse: 0.0450336\tvalid_0's l2: 0.00202803\n",
      "[299]\tvalid_0's rmse: 0.0450435\tvalid_0's l2: 0.00202892\n",
      "[300]\tvalid_0's rmse: 0.0450427\tvalid_0's l2: 0.00202885\n",
      "[301]\tvalid_0's rmse: 0.0450412\tvalid_0's l2: 0.00202871\n",
      "[302]\tvalid_0's rmse: 0.0450446\tvalid_0's l2: 0.00202902\n",
      "[303]\tvalid_0's rmse: 0.0450448\tvalid_0's l2: 0.00202904\n",
      "[304]\tvalid_0's rmse: 0.0450488\tvalid_0's l2: 0.00202939\n",
      "[305]\tvalid_0's rmse: 0.0450391\tvalid_0's l2: 0.00202852\n",
      "[306]\tvalid_0's rmse: 0.0450387\tvalid_0's l2: 0.00202848\n",
      "[307]\tvalid_0's rmse: 0.0450358\tvalid_0's l2: 0.00202822\n",
      "[308]\tvalid_0's rmse: 0.0450334\tvalid_0's l2: 0.002028\n",
      "[309]\tvalid_0's rmse: 0.0450342\tvalid_0's l2: 0.00202807\n",
      "[310]\tvalid_0's rmse: 0.0450372\tvalid_0's l2: 0.00202835\n",
      "[311]\tvalid_0's rmse: 0.0450267\tvalid_0's l2: 0.00202741\n",
      "[312]\tvalid_0's rmse: 0.0450308\tvalid_0's l2: 0.00202778\n",
      "[313]\tvalid_0's rmse: 0.0450331\tvalid_0's l2: 0.00202798\n",
      "[314]\tvalid_0's rmse: 0.0450368\tvalid_0's l2: 0.00202831\n",
      "[315]\tvalid_0's rmse: 0.0450377\tvalid_0's l2: 0.0020284\n",
      "[316]\tvalid_0's rmse: 0.0450314\tvalid_0's l2: 0.00202783\n",
      "[317]\tvalid_0's rmse: 0.0450356\tvalid_0's l2: 0.00202821\n",
      "[318]\tvalid_0's rmse: 0.0450351\tvalid_0's l2: 0.00202816\n",
      "[319]\tvalid_0's rmse: 0.0450276\tvalid_0's l2: 0.00202748\n",
      "[320]\tvalid_0's rmse: 0.0450354\tvalid_0's l2: 0.00202818\n",
      "[321]\tvalid_0's rmse: 0.0450383\tvalid_0's l2: 0.00202845\n",
      "[322]\tvalid_0's rmse: 0.0450416\tvalid_0's l2: 0.00202875\n",
      "[323]\tvalid_0's rmse: 0.0450431\tvalid_0's l2: 0.00202888\n",
      "[324]\tvalid_0's rmse: 0.0450461\tvalid_0's l2: 0.00202915\n",
      "[325]\tvalid_0's rmse: 0.0450493\tvalid_0's l2: 0.00202944\n",
      "[326]\tvalid_0's rmse: 0.0450473\tvalid_0's l2: 0.00202926\n",
      "[327]\tvalid_0's rmse: 0.0450586\tvalid_0's l2: 0.00203028\n",
      "[328]\tvalid_0's rmse: 0.0450496\tvalid_0's l2: 0.00202947\n",
      "[329]\tvalid_0's rmse: 0.0450465\tvalid_0's l2: 0.00202918\n",
      "[330]\tvalid_0's rmse: 0.0450387\tvalid_0's l2: 0.00202849\n",
      "[331]\tvalid_0's rmse: 0.0450398\tvalid_0's l2: 0.00202858\n",
      "[332]\tvalid_0's rmse: 0.0450549\tvalid_0's l2: 0.00202994\n",
      "[333]\tvalid_0's rmse: 0.0450618\tvalid_0's l2: 0.00203056\n",
      "[334]\tvalid_0's rmse: 0.0450585\tvalid_0's l2: 0.00203027\n",
      "[335]\tvalid_0's rmse: 0.0450565\tvalid_0's l2: 0.00203009\n",
      "[336]\tvalid_0's rmse: 0.0450545\tvalid_0's l2: 0.00202991\n",
      "[337]\tvalid_0's rmse: 0.0450563\tvalid_0's l2: 0.00203007\n",
      "[338]\tvalid_0's rmse: 0.0450599\tvalid_0's l2: 0.0020304\n",
      "[339]\tvalid_0's rmse: 0.0450702\tvalid_0's l2: 0.00203132\n",
      "[340]\tvalid_0's rmse: 0.045061\tvalid_0's l2: 0.00203049\n",
      "[341]\tvalid_0's rmse: 0.0450672\tvalid_0's l2: 0.00203105\n",
      "[342]\tvalid_0's rmse: 0.0450562\tvalid_0's l2: 0.00203006\n",
      "[343]\tvalid_0's rmse: 0.0450619\tvalid_0's l2: 0.00203057\n",
      "[344]\tvalid_0's rmse: 0.0450551\tvalid_0's l2: 0.00202996\n",
      "[345]\tvalid_0's rmse: 0.0450549\tvalid_0's l2: 0.00202995\n",
      "[346]\tvalid_0's rmse: 0.045044\tvalid_0's l2: 0.00202896\n",
      "[347]\tvalid_0's rmse: 0.0450448\tvalid_0's l2: 0.00202903\n",
      "[348]\tvalid_0's rmse: 0.045026\tvalid_0's l2: 0.00202734\n",
      "[349]\tvalid_0's rmse: 0.0450298\tvalid_0's l2: 0.00202769\n",
      "[350]\tvalid_0's rmse: 0.0450256\tvalid_0's l2: 0.0020273\n",
      "[351]\tvalid_0's rmse: 0.0450188\tvalid_0's l2: 0.0020267\n",
      "[352]\tvalid_0's rmse: 0.0450335\tvalid_0's l2: 0.00202802\n",
      "[353]\tvalid_0's rmse: 0.0450369\tvalid_0's l2: 0.00202833\n",
      "[354]\tvalid_0's rmse: 0.0450349\tvalid_0's l2: 0.00202814\n",
      "[355]\tvalid_0's rmse: 0.0450426\tvalid_0's l2: 0.00202884\n",
      "[356]\tvalid_0's rmse: 0.0450544\tvalid_0's l2: 0.0020299\n",
      "[357]\tvalid_0's rmse: 0.0450552\tvalid_0's l2: 0.00202997\n",
      "[358]\tvalid_0's rmse: 0.0450609\tvalid_0's l2: 0.00203049\n",
      "[359]\tvalid_0's rmse: 0.0450622\tvalid_0's l2: 0.0020306\n",
      "[360]\tvalid_0's rmse: 0.0450573\tvalid_0's l2: 0.00203016\n",
      "[361]\tvalid_0's rmse: 0.0450741\tvalid_0's l2: 0.00203167\n",
      "[362]\tvalid_0's rmse: 0.0450642\tvalid_0's l2: 0.00203079\n",
      "[363]\tvalid_0's rmse: 0.0450633\tvalid_0's l2: 0.0020307\n",
      "[364]\tvalid_0's rmse: 0.0450498\tvalid_0's l2: 0.00202948\n",
      "[365]\tvalid_0's rmse: 0.045051\tvalid_0's l2: 0.00202959\n",
      "[366]\tvalid_0's rmse: 0.0450544\tvalid_0's l2: 0.0020299\n",
      "[367]\tvalid_0's rmse: 0.0450581\tvalid_0's l2: 0.00203023\n",
      "[368]\tvalid_0's rmse: 0.0450594\tvalid_0's l2: 0.00203035\n",
      "[369]\tvalid_0's rmse: 0.0450534\tvalid_0's l2: 0.00202981\n",
      "[370]\tvalid_0's rmse: 0.0450394\tvalid_0's l2: 0.00202855\n",
      "[371]\tvalid_0's rmse: 0.0450485\tvalid_0's l2: 0.00202937\n",
      "[372]\tvalid_0's rmse: 0.0450474\tvalid_0's l2: 0.00202927\n",
      "[373]\tvalid_0's rmse: 0.0450395\tvalid_0's l2: 0.00202856\n",
      "[374]\tvalid_0's rmse: 0.045046\tvalid_0's l2: 0.00202914\n",
      "[375]\tvalid_0's rmse: 0.0450278\tvalid_0's l2: 0.0020275\n",
      "[376]\tvalid_0's rmse: 0.04503\tvalid_0's l2: 0.0020277\n",
      "[377]\tvalid_0's rmse: 0.045038\tvalid_0's l2: 0.00202842\n",
      "[378]\tvalid_0's rmse: 0.0450099\tvalid_0's l2: 0.00202589\n",
      "[379]\tvalid_0's rmse: 0.0450119\tvalid_0's l2: 0.00202607\n",
      "[380]\tvalid_0's rmse: 0.0450008\tvalid_0's l2: 0.00202507\n",
      "[381]\tvalid_0's rmse: 0.0450002\tvalid_0's l2: 0.00202502\n",
      "[382]\tvalid_0's rmse: 0.0450052\tvalid_0's l2: 0.00202547\n",
      "[383]\tvalid_0's rmse: 0.044999\tvalid_0's l2: 0.00202491\n",
      "[384]\tvalid_0's rmse: 0.0449939\tvalid_0's l2: 0.00202445\n",
      "[385]\tvalid_0's rmse: 0.0449947\tvalid_0's l2: 0.00202452\n",
      "[386]\tvalid_0's rmse: 0.0449923\tvalid_0's l2: 0.0020243\n",
      "[387]\tvalid_0's rmse: 0.0450049\tvalid_0's l2: 0.00202544\n",
      "[388]\tvalid_0's rmse: 0.0450167\tvalid_0's l2: 0.0020265\n",
      "[389]\tvalid_0's rmse: 0.0450241\tvalid_0's l2: 0.00202717\n",
      "[390]\tvalid_0's rmse: 0.0450246\tvalid_0's l2: 0.00202721\n",
      "[391]\tvalid_0's rmse: 0.045022\tvalid_0's l2: 0.00202698\n",
      "[392]\tvalid_0's rmse: 0.0450065\tvalid_0's l2: 0.00202558\n",
      "[393]\tvalid_0's rmse: 0.0450114\tvalid_0's l2: 0.00202602\n",
      "[394]\tvalid_0's rmse: 0.04502\tvalid_0's l2: 0.0020268\n",
      "[395]\tvalid_0's rmse: 0.0450202\tvalid_0's l2: 0.00202682\n",
      "[396]\tvalid_0's rmse: 0.0450192\tvalid_0's l2: 0.00202673\n",
      "[397]\tvalid_0's rmse: 0.0450253\tvalid_0's l2: 0.00202727\n",
      "[398]\tvalid_0's rmse: 0.0450273\tvalid_0's l2: 0.00202746\n",
      "[399]\tvalid_0's rmse: 0.0450393\tvalid_0's l2: 0.00202854\n",
      "[400]\tvalid_0's rmse: 0.0450392\tvalid_0's l2: 0.00202853\n",
      "[401]\tvalid_0's rmse: 0.0450387\tvalid_0's l2: 0.00202848\n",
      "[402]\tvalid_0's rmse: 0.0450416\tvalid_0's l2: 0.00202874\n",
      "[403]\tvalid_0's rmse: 0.045048\tvalid_0's l2: 0.00202932\n",
      "[404]\tvalid_0's rmse: 0.0450482\tvalid_0's l2: 0.00202934\n",
      "[405]\tvalid_0's rmse: 0.0450416\tvalid_0's l2: 0.00202875\n",
      "[406]\tvalid_0's rmse: 0.0450434\tvalid_0's l2: 0.00202891\n",
      "[407]\tvalid_0's rmse: 0.0450427\tvalid_0's l2: 0.00202884\n",
      "[408]\tvalid_0's rmse: 0.0450554\tvalid_0's l2: 0.00202999\n",
      "[409]\tvalid_0's rmse: 0.0450467\tvalid_0's l2: 0.0020292\n",
      "[410]\tvalid_0's rmse: 0.0450458\tvalid_0's l2: 0.00202913\n",
      "[411]\tvalid_0's rmse: 0.0450443\tvalid_0's l2: 0.00202899\n",
      "[412]\tvalid_0's rmse: 0.0450441\tvalid_0's l2: 0.00202897\n",
      "[413]\tvalid_0's rmse: 0.0450422\tvalid_0's l2: 0.0020288\n",
      "[414]\tvalid_0's rmse: 0.0450545\tvalid_0's l2: 0.00202991\n",
      "[415]\tvalid_0's rmse: 0.0450576\tvalid_0's l2: 0.00203018\n",
      "[416]\tvalid_0's rmse: 0.0450432\tvalid_0's l2: 0.00202889\n",
      "[417]\tvalid_0's rmse: 0.0450471\tvalid_0's l2: 0.00202924\n",
      "[418]\tvalid_0's rmse: 0.045051\tvalid_0's l2: 0.00202959\n",
      "[419]\tvalid_0's rmse: 0.0450467\tvalid_0's l2: 0.00202921\n",
      "[420]\tvalid_0's rmse: 0.0450409\tvalid_0's l2: 0.00202868\n",
      "[421]\tvalid_0's rmse: 0.0450408\tvalid_0's l2: 0.00202868\n",
      "[422]\tvalid_0's rmse: 0.0450478\tvalid_0's l2: 0.0020293\n",
      "[423]\tvalid_0's rmse: 0.0450496\tvalid_0's l2: 0.00202947\n",
      "[424]\tvalid_0's rmse: 0.0450436\tvalid_0's l2: 0.00202893\n",
      "[425]\tvalid_0's rmse: 0.0450389\tvalid_0's l2: 0.00202851\n",
      "[426]\tvalid_0's rmse: 0.0450398\tvalid_0's l2: 0.00202858\n",
      "[427]\tvalid_0's rmse: 0.0450456\tvalid_0's l2: 0.00202911\n",
      "[428]\tvalid_0's rmse: 0.0450469\tvalid_0's l2: 0.00202922\n",
      "[429]\tvalid_0's rmse: 0.0450467\tvalid_0's l2: 0.0020292\n",
      "[430]\tvalid_0's rmse: 0.0450408\tvalid_0's l2: 0.00202867\n",
      "[431]\tvalid_0's rmse: 0.0450433\tvalid_0's l2: 0.0020289\n",
      "[432]\tvalid_0's rmse: 0.0450456\tvalid_0's l2: 0.00202911\n",
      "[433]\tvalid_0's rmse: 0.0450444\tvalid_0's l2: 0.00202899\n",
      "[434]\tvalid_0's rmse: 0.045044\tvalid_0's l2: 0.00202896\n",
      "[435]\tvalid_0's rmse: 0.0450523\tvalid_0's l2: 0.00202971\n",
      "[436]\tvalid_0's rmse: 0.04505\tvalid_0's l2: 0.00202951\n",
      "Early stopping, best iteration is:\n",
      "[386]\tvalid_0's rmse: 0.0449923\tvalid_0's l2: 0.0020243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytre=0.8,\n",
       "       colsample_bytree=1.0, importance_type='split', learning_rate=0.1,\n",
       "       max_depth=3, min_child_samples=20, min_child_weight=0.001,\n",
       "       min_split_gain=0.0, n_estimators=30000, n_jobs=-1, num_leaves=31,\n",
       "       objective='regression', random_state=None, reg_alpha=0.0,\n",
       "       reg_lambda=0.0, silent=True, subsample=0.8,\n",
       "       subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.fit(X_train, Y_train, eval_set=[(X_valid, Y_valid)], eval_metric='rmse', early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04499226214211021"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(Y_valid, gbm.predict(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08463725683992336"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(Y_valid, np.zeros(Y_valid.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(gbm.predict(X_test), index=test.index,columns=['target'])\n",
    "submit.reset_index(level=0, inplace=True)\n",
    "submit.index.name = \"\"\n",
    "submit.to_csv('simple_lgb_submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.025831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.048605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.002872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.034140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.008871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.021381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.018675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.067693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.038082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.055460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>-0.064273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>-0.066490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>-0.011513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.177741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>-0.060704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>-0.023253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>-0.040230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>-0.050657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>-0.029022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>-0.046705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>-0.049747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.158462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.172270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>-0.003871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.007632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>-0.037087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.038704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.157561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>-0.037135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>-0.024651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>2474</td>\n",
       "      <td>-0.048605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>2475</td>\n",
       "      <td>-0.034880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>2476</td>\n",
       "      <td>-0.068512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>2477</td>\n",
       "      <td>-0.048526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>2478</td>\n",
       "      <td>0.014235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>2479</td>\n",
       "      <td>-0.065792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>2480</td>\n",
       "      <td>-0.072320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>2481</td>\n",
       "      <td>0.006711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>2482</td>\n",
       "      <td>-0.018675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>2483</td>\n",
       "      <td>-0.007615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>2484</td>\n",
       "      <td>-0.037964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>2485</td>\n",
       "      <td>0.131192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>2486</td>\n",
       "      <td>-0.043663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487</th>\n",
       "      <td>2487</td>\n",
       "      <td>-0.002113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2488</th>\n",
       "      <td>2488</td>\n",
       "      <td>-0.031347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2489</th>\n",
       "      <td>2489</td>\n",
       "      <td>-0.036238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2490</th>\n",
       "      <td>2490</td>\n",
       "      <td>0.202033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>2491</td>\n",
       "      <td>-0.048796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492</th>\n",
       "      <td>2492</td>\n",
       "      <td>0.020284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>2493</td>\n",
       "      <td>-0.038297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>2494</td>\n",
       "      <td>-0.008376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>2495</td>\n",
       "      <td>-0.040315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>2496</td>\n",
       "      <td>0.127924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>2497</td>\n",
       "      <td>-0.080760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>2498</td>\n",
       "      <td>-0.081290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>2499</td>\n",
       "      <td>-0.021310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>2500</td>\n",
       "      <td>-0.044029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>2501</td>\n",
       "      <td>0.165230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>2502</td>\n",
       "      <td>0.033407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>2503</td>\n",
       "      <td>0.125433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2504 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index    target\n",
       "                     \n",
       "0         0 -0.025831\n",
       "1         1 -0.048605\n",
       "2         2 -0.002872\n",
       "3         3 -0.034140\n",
       "4         4  0.008871\n",
       "5         5 -0.021381\n",
       "6         6 -0.018675\n",
       "7         7 -0.067693\n",
       "8         8 -0.038082\n",
       "9         9 -0.055460\n",
       "10       10 -0.064273\n",
       "11       11 -0.066490\n",
       "12       12 -0.011513\n",
       "13       13  0.177741\n",
       "14       14 -0.060704\n",
       "15       15 -0.023253\n",
       "16       16 -0.040230\n",
       "17       17 -0.050657\n",
       "18       18 -0.029022\n",
       "19       19 -0.046705\n",
       "20       20 -0.049747\n",
       "21       21  0.158462\n",
       "22       22  0.172270\n",
       "23       23 -0.003871\n",
       "24       24  0.007632\n",
       "25       25 -0.037087\n",
       "26       26  0.038704\n",
       "27       27  0.157561\n",
       "28       28 -0.037135\n",
       "29       29 -0.024651\n",
       "...     ...       ...\n",
       "2474   2474 -0.048605\n",
       "2475   2475 -0.034880\n",
       "2476   2476 -0.068512\n",
       "2477   2477 -0.048526\n",
       "2478   2478  0.014235\n",
       "2479   2479 -0.065792\n",
       "2480   2480 -0.072320\n",
       "2481   2481  0.006711\n",
       "2482   2482 -0.018675\n",
       "2483   2483 -0.007615\n",
       "2484   2484 -0.037964\n",
       "2485   2485  0.131192\n",
       "2486   2486 -0.043663\n",
       "2487   2487 -0.002113\n",
       "2488   2488 -0.031347\n",
       "2489   2489 -0.036238\n",
       "2490   2490  0.202033\n",
       "2491   2491 -0.048796\n",
       "2492   2492  0.020284\n",
       "2493   2493 -0.038297\n",
       "2494   2494 -0.008376\n",
       "2495   2495 -0.040315\n",
       "2496   2496  0.127924\n",
       "2497   2497 -0.080760\n",
       "2498   2498 -0.081290\n",
       "2499   2499 -0.021310\n",
       "2500   2500 -0.044029\n",
       "2501   2501  0.165230\n",
       "2502   2502  0.033407\n",
       "2503   2503  0.125433\n",
       "\n",
       "[2504 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
